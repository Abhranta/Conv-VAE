{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the notebook for the dataloader and the transformations on the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from PIL import ImageFile\n",
    "import csv\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_set(Dataset):\n",
    "    def __init__(self , csv_file  , root_dir , transform = None ):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations) \n",
    "    \n",
    "    \n",
    "    def __getitem__(self , index):\n",
    "        try:\n",
    "            img_path = os.path.join(self.root_dir , self.annotations.iloc[index , 0])\n",
    "            image = Image.open(img_path )\n",
    "\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "      \n",
    "        except:\n",
    "            return None\n",
    "\n",
    "        return image\n",
    "\n",
    "#The batch size chosen here is 1. This reduces the GPU usage.\n",
    "batch_size = 1\n",
    "def collate_fn(batch):\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are creating a csv file which will contain the names of the images in your training data.\n",
    "#This csv file will be used to fetch the data and add it tooe dataloader.\n",
    "with open('image_annotation.csv', 'w', newline='') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    \n",
    "    \n",
    "    for filename in os.listdir(r\"C:\\Users\\Abhrant\\Desktop\\abhrant\\work\\DEEP_LEARNING\\FaceDataset\"):\n",
    "        \n",
    "            data.append(filename)\n",
    "            writer.writerow(data)\n",
    "            data=[]\n",
    "writeFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "#Here , various transformations are applied to the images.\n",
    "#The images are resized to (64x64) each\n",
    "#Then they are converted to tensors \n",
    "#Then they are normalized with the mean accross all channels being 0 and the variance accross all channels being 1\n",
    "\n",
    "my_transforms = transforms.Compose([\n",
    "    transforms.Resize((64,64)) , \n",
    "    transforms.ToTensor() , \n",
    "    transforms.Normalize((0.0 , 0.0 , 0.0), (1.0 , 1.0 , 1.0)),\n",
    "])\n",
    "\n",
    "data=[]\n",
    "\n",
    "colored_dataset = data_set(csv_file = \"image_annotation.csv\" , root_dir = r\"C:\\Users\\Abhrant\\Desktop\\abhrant\\work\\DEEP_LEARNING\\FaceDataset\" , \n",
    "                          transform = my_transforms)\n",
    "\n",
    "\n",
    "\n",
    "image_loader = DataLoader(dataset = colored_dataset , collate_fn = collate_fn ,  batch_size = batch_size , shuffle = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
